{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Work with environments\n",
    "\n",
    "\n",
    "When you run a script as an Azure Machine Learning job, you need to define the execution context for the job run. One key configuration is the compute target on which the script will be run. This could be the local workstation (in this case the compute instance), or a remote compute target such as the Azure Machine Learning managed compute cluster that is provisioned on-demand.\n",
    "\n",
    "In this notebook, you'll create a compute cluster and explore compute targets for jobs.\n",
    "\n",
    "## Before you start\n",
    "\n",
    "You'll need the latest version of the  **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
    "\n",
    "> **Note**:\n",
    "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1665745893251
    },
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-06-17T00:26:19.476521900Z",
     "start_time": "2024-06-17T00:26:11.457690100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: azure-ai-ml\n",
      "Version: 1.14.0\n",
      "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
      "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
      "Author: Microsoft Corporation\n",
      "Author-email: azuresdkengsysadmins@microsoft.com\n",
      "License: MIT License\n",
      "Location: c:\\users\\sirip\\miniconda3\\envs\\myenv\\lib\\site-packages\n",
      "Requires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, opencensus-ext-logging, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show azure-ai-ml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1665745927409
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-06-17T00:27:11.065301400Z",
     "start_time": "2024-06-17T00:27:02.607067600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x000002E594593040>,\n         subscription_id=73a3b9d4-4ac9-4810-8752-0f69cc4ac4a3,\n         resource_group_name=DS_Team,\n         workspace_name=mlw-example)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import command\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "subscription_id = os.getenv('SUBSCRIPTION_ID')\n",
    "resource_group = os.getenv('RESOURCE_GROUP')\n",
    "workspace = os.getenv('WORKSPACE')\n",
    "storage_account_name = os.getenv('STORAGE_ACCOUNT_NAME')\n",
    "storage_account_key = os.getenv('STORAGE_ACCOUNT_KEY')\n",
    "\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "\n",
    "ml_client"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "To view all available environments within the Azure Machine Learning workspace, you can list the environments in the studio, using the Azure CLI, or the Python SDK.\n",
    "\n",
    "For example, to list the environments using the Python SDK:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Environment({'arm_type': 'environment_version', 'latest_version': '10', 'image': None, 'intellectual_property': None, 'is_anonymous': False, 'auto_increment_version': True, 'auto_delete_setting': None, 'name': 'AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu', 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': False, 'id': '/subscriptions/73a3b9d4-4ac9-4810-8752-0f69cc4ac4a3/resourceGroups/DS_Team/providers/Microsoft.MachineLearningServices/workspaces/mlw-example/environments/AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu', 'Resource__source_path': '', 'base_path': 'C:\\\\Users\\\\sirip\\\\Documents\\\\azure-machine-learning\\\\azure-ml-labs\\\\Labs\\\\04', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x000002E59460CF70>, 'serialize': <msrest.serialization.Serializer object at 0x000002E59E6F13C0>, 'version': None, 'conda_file': None, 'build': None, 'inference_config': None, 'os_type': None, 'conda_file_path': None, 'path': None, 'datastore': None, 'upload_hash': None, 'translated_conda_file': None})]\n"
     ]
    }
   ],
   "source": [
    "envs = ml_client.environments.list()\n",
    "print(list(envs))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-17T01:30:43.159578900Z",
     "start_time": "2024-06-17T01:30:42.766157800Z"
    }
   },
   "execution_count": 8
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a script as a job\n",
    "\n",
    "To train a model, you'll first create the **diabetes_training.py** script in the **src** folder. The script uses the **diabetes.csv** file in the same folder as the training data.\n",
    "\n",
    "Note that you import libraries at the beginning of the script. Functions from these libraries are used to process the data and train the model. Whatever compute you use to run the script must have these libraries installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-06-17T00:27:56.213011100Z",
     "start_time": "2024-06-17T00:27:56.181322100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/diabetes-training.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/diabetes-training.py\n",
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('src/diabetes.csv')\n",
    "print(diabetes)\n",
    "# separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# set regularization hyperparameter\n",
    "reg = 0.01\n",
    "\n",
    "# train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you create the script, you can run the script as a job. The script uses common libraries. So you can use a curated environment that includes pandas, numpy, and scikit-learn, among others.\n",
    "\n",
    "The job uses the latest version of the curated environment: `AzureML-sklearn-0.24-ubuntu18.04-py37-cpu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python diabetes-training.py\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-curated-env\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the job is running, you can already run the next cells."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List environments\n",
    "\n",
    "Let's explore the environments within the workspace. \n",
    "\n",
    "In the previous job, you used one of the curated environments. To explore all environments that already exist in the workspace, you can list the environments: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-06-17T02:32:56.206414400Z",
     "start_time": "2024-06-17T02:32:52.948007400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu\n"
     ]
    }
   ],
   "source": [
    "envs = ml_client.environments.list()\n",
    "for env in envs:\n",
    "    print(env.name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all curated environments have names that begin **AzureML-** (you can't use this prefix for your own environments).\n",
    "\n",
    "To review a specific environment, you can retrieve an environment by its name and version. For example, you can retrieve the *description* and *tags* of the curated environment you used for the previous job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-06-17T02:33:21.218845700Z",
     "start_time": "2024-06-17T02:33:20.950746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An environment for tasks such as regression, clustering, and classification with Scikit-learn. Contains the Azure ML SDK and additional python packages. {'Scikit-learn': '0.24.1', 'OS': 'Ubuntu18.04', 'Training': ''}\n"
     ]
    }
   ],
   "source": [
    "env = ml_client.environments.get(\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu\", version=44)\n",
    "print(env.description, env.tags)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and use a custom environment\n",
    "\n",
    "If a curated environment doesn't include all the Python packages you need to run your script, you can create your own custom environment. By listing all necessary packages in an environment, you can easily re-run your scripts. All the dependencies are stored in the environment which you can then specify in the job configuration, independent of the compute you use.\n",
    "\n",
    "For example, you can create an environment simply from a Docker image. Certain frameworks like PyTorch will have a public Docker image that already includes everything you need. \n",
    "\n",
    "Let's create an environment from a Docker image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env_docker_image = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    name=\"docker-image-example\",\n",
    "    description=\"Environment created from a Docker image.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is now registered in your workspace and you can reference it when you run a script as a job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python diabetes-training.py\",\n",
    "    environment=\"docker-image-example:1\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-custom-env\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red;font-size:120%;background-color:yellow;font-weight:bold\"> The job will quickly fail! Review the error message. </p>\n",
    "\n",
    "The error message will tell you that there is no module named pandas. There are two possible causes for such an error:\n",
    "\n",
    "- The script uses pandas but didn't import the library (`import pandas as pd`). \n",
    "- The script does import the library at the top of the script but the compute didn't have the library installed (`pip install pandas`).\n",
    "\n",
    "After reviewing the `diabetes-training.py` script you can observe the script is correct, which means the library wasn't installed. In other words, the environment didn't include the necessary packages.\n",
    "\n",
    "Let's create a new environment, using the base Docker image used in the previous job. Now, you'll add a conda specification to ensure the necessary packages will be installed. First, run the following cell to create the conda specification file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile src/conda-env.yml\n",
    "name: basic-env-cpu\n",
    "channels:\n",
    "  - conda-forge\n",
    "dependencies:\n",
    "  - python=3.7\n",
    "  - scikit-learn\n",
    "  - pandas\n",
    "  - numpy\n",
    "  - matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all necessary dependencies are included in the conda specification file for the script to run successfully.\n",
    "\n",
    "Create a new environment using the base Docker image **and** the conda specification file to add the necessary dependencies. Azure Machine Learning will build the conda environment on top of the Docker image you provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\",\n",
    "    conda_file=\"./src/conda-env.yml\",\n",
    "    name=\"docker-image-plus-conda-example\",\n",
    "    description=\"Environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can submit a job with the new environment to run the script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python diabetes-training.py\",\n",
    "    environment=\"docker-image-plus-conda-example:1\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-custom-env\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    ")\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submitting the job with the new custom environment triggers the build of the environment. The first time you use a newly created environment, it can take 10-15 minutes to build the environment, which also means your job will take longer to complete. \n",
    "\n",
    "You can also choose to manually trigger the build of the environment before you submit a job. The environment only needs to be built the first time you use it. \n",
    "\n",
    "When the job triggers the build of a new environment, you can review the logs of the build in the **Outputs + logs** tab of the job. Open **azureml-logs/20_image_build_log.txt** to inspect the logs of the environment build. \n",
    "\n",
    "![Screenshot build logs](./images/screenshot-logs.png)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
