{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log models with MLflow\n",
    "\n",
    "You can use MLflow in Azure Machine Learning to log models. When you log a model as a model instead of an artifact, a MLmodel is created in the output directory. The MLmodel file contains all the model's metadata. You can customize the model's signature when logging the model.\n",
    "\n",
    "## Before you start\n",
    "\n",
    "You'll need the latest version of the **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
    "\n",
    "> **Note**:\n",
    "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip show azure-ai-ml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1663753569264
    },
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T05:32:25.730202600Z",
     "start_time": "2024-06-19T05:32:16.635886900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x00000260A595A440>,\n         subscription_id=73a3b9d4-4ac9-4810-8752-0f69cc4ac4a3,\n         resource_group_name=DS_Team,\n         workspace_name=mlw-example)"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import command\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "subscription_id = os.getenv('SUBSCRIPTION_ID')\n",
    "resource_group = os.getenv('RESOURCE_GROUP')\n",
    "workspace = os.getenv('WORKSPACE')\n",
    "storage_account_name = os.getenv('STORAGE_ACCOUNT_NAME')\n",
    "storage_account_key = os.getenv('STORAGE_ACCOUNT_KEY')\n",
    "\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "\n",
    "ml_client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autologging with MLflow\n",
    "\n",
    "When you use autologging, your model is automatically logged. The model flavor and schema is inferred. \n",
    "\n",
    "Run the following cell to create the **train-model-autolog.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T05:33:07.841401900Z",
     "start_time": "2024-06-19T05:33:07.828340100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src folder created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# create a folder for the script files\n",
    "script_folder = 'src'\n",
    "os.makedirs(script_folder, exist_ok=True)\n",
    "print(script_folder, 'folder created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T05:33:20.856861600Z",
     "start_time": "2024-06-19T05:33:20.848793800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src/train-model-autolog.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train-model-autolog.py\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main(args):\n",
    "    # enable autologging\n",
    "    mlflow.autolog()\n",
    "\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    eval_model(model, X_test, y_test)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
    "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
    "    print(\"Training model...\")\n",
    "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate accuracy\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
    "                        type=float, default=0.01)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can submit the script as a command job.\n",
    "\n",
    "Run the cell below to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T05:33:55.476710200Z",
     "start_time": "2024-06-19T05:33:42.148522300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001B[32mUploading src (0.45 MBs): 100%|##########| 450107/450107 [00:01<00:00, 403316.37it/s]\n",
      "\u001B[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monitor your job at https://ml.azure.com/runs/heroic_helmet_119w0b3mdt?wsid=/subscriptions/73a3b9d4-4ac9-4810-8752-0f69cc4ac4a3/resourcegroups/DS_Team/workspaces/mlw-example&tid=a8eec281-aaa3-4dae-ac9b-9a398b9215e7\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train-model-autolog.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"basic-example\",\n",
    "    display_name=\"diabetes-train-autolog\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Studio, navigate to the **diabetes-train-autolog** job to explore the overview of the command job you ran. Find the logged artifacts in the **Outputs + logs** tab. Select the `model` folder to find the `MLmodel` file and explore its contents."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the flavor with autologging\n",
    "\n",
    "You can use autologging, but still specify the flavor of the model. In the example, the model's flavor is scikit-learn.\n",
    "\n",
    "Run the following cell to create the **train-model-sklearn.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train-model-sklearn.py\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def main(args):\n",
    "    # enable autologging\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    eval_model(model, X_test, y_test)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
    "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
    "    print(\"Training model...\")\n",
    "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate accuracy\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    "\n",
    "    # calculate AUC\n",
    "    y_scores = model.predict_proba(X_test)\n",
    "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "    print('AUC: ' + str(auc))\n",
    "\n",
    "    # plot ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "    fig = plt.figure(figsize=(6, 4))\n",
    "    # Plot the diagonal 50% line\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    # Plot the FPR and TPR achieved by our model\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.savefig(\"ROC-Curve.png\") \n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
    "                        type=float, default=0.01)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can submit the script as a command job.\n",
    "\n",
    "Run the cell below to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train-model-sklearn.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-sklearn\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Studio, navigate to the **diabetes-train-sklearn** job to explore the overview of the command job you ran. Find the logged artifacts in the **Outputs + logs** tab. Select the `model` folder to find the `MLmodel` file and explore its contents.\n",
    "\n",
    "Compare the `MLmodel` files of the previous two runs. You'll notice that they're the same, indicating that MLflow's autolog feature correctly inferred the model's flavor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize the model with an inferred signature\n",
    "\n",
    "You can manually log the model when using autologging. By using 'log_models=False', autologging will not log the model. You'll create a signature by inferring it from the training dataset and predicted results. And finally, you'll log the scikit-learn model.\n",
    "\n",
    "Run the following cell to create the **train-model-infer.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train-model-infer.py\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "def main(args):\n",
    "    # enable autologging\n",
    "    mlflow.autolog(log_models=False)\n",
    "\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # evaluate model\n",
    "    y_hat = eval_model(model, X_test, y_test)\n",
    "\n",
    "    # create the signature by inferring it from the datasets\n",
    "    signature = infer_signature(X_train, y_hat)\n",
    "\n",
    "    # manually log the model\n",
    "    mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
    "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
    "    print(\"Training model...\")\n",
    "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate accuracy\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    " \n",
    "    return y_hat\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
    "                        type=float, default=0.01)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can submit the script as a command job.\n",
    "\n",
    "Run the cell below to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train-model-infer.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-infer\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Studio, navigate to the **diabetes-train-infer** job to explore the overview of the command job you ran. Find the logged artifacts in the **Outputs + logs** tab. Select the `model` folder to find the `MLmodel` file and explore its contents.\n",
    "\n",
    "Compare the `MLmodel` files with the previous two runs. You'll notice that they're all the same, indicating that MLflow's autolog feature correctly inferred the model's signature too."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize the model with a defined signature\n",
    "\n",
    "You can manually log the model when using autologging. By using 'log_models=False', autologging will not log the model. You'll create a signature by inferring it from the training dataset and predicted results. And finally, you'll log the scikit-learn model.\n",
    "\n",
    "Run the following cell to create the **train-model-infer.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train-model-signature.py\n",
    "# import libraries\n",
    "import mlflow\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "def main(args):\n",
    "    # enable autologging\n",
    "    mlflow.autolog(log_models=False)\n",
    "\n",
    "    # read data\n",
    "    df = get_data(args.training_data)\n",
    "\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # train model\n",
    "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # evaluate model\n",
    "    y_hat = eval_model(model, X_test, y_test)\n",
    "\n",
    "    # create the signature manually\n",
    "    input_schema = Schema([\n",
    "    ColSpec(\"integer\", \"Pregnancies\"),\n",
    "    ColSpec(\"integer\", \"PlasmaGlucose\"),\n",
    "    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n",
    "    ColSpec(\"integer\", \"TricepsThickness\"),\n",
    "    ColSpec(\"integer\", \"DiastolicBloodPressure\"),\n",
    "    ColSpec(\"integer\", \"SerumInsulin\"),\n",
    "    ColSpec(\"double\", \"BMI\"),\n",
    "    ColSpec(\"double\", \"DiabetesPedigree\"),\n",
    "    ColSpec(\"integer\", \"Age\"),\n",
    "    ])\n",
    "\n",
    "    output_schema = Schema([ColSpec(\"boolean\")])\n",
    "\n",
    "    # Create the signature object\n",
    "    signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "    # manually log the model\n",
    "    mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
    "\n",
    "# function that reads the data\n",
    "def get_data(path):\n",
    "    print(\"Reading data...\")\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# function that splits the data\n",
    "def split_data(df):\n",
    "    print(\"Splitting data...\")\n",
    "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
    "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# function that trains the model\n",
    "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
    "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
    "    print(\"Training model...\")\n",
    "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "    return model\n",
    "\n",
    "# function that evaluates the model\n",
    "def eval_model(model, X_test, y_test):\n",
    "    # calculate accuracy\n",
    "    y_hat = model.predict(X_test)\n",
    "    acc = np.average(y_hat == y_test)\n",
    "    print('Accuracy:', acc)\n",
    " \n",
    "    return y_hat\n",
    "\n",
    "def parse_args():\n",
    "    # setup arg parser\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # add arguments\n",
    "    parser.add_argument(\"--training_data\", dest='training_data',\n",
    "                        type=str)\n",
    "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
    "                        type=float, default=0.01)\n",
    "\n",
    "    # parse args\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # return args\n",
    "    return args\n",
    "\n",
    "# run script\n",
    "if __name__ == \"__main__\":\n",
    "    # add space in logs\n",
    "    print(\"\\n\\n\")\n",
    "    print(\"*\" * 60)\n",
    "\n",
    "    # parse args\n",
    "    args = parse_args()\n",
    "\n",
    "    # run main function\n",
    "    main(args)\n",
    "\n",
    "    # add space in logs\n",
    "    print(\"*\" * 60)\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you can submit the script as a command job.\n",
    "\n",
    "Run the cell below to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import command\n",
    "\n",
    "# configure job\n",
    "\n",
    "job = command(\n",
    "    code=\"./src\",\n",
    "    command=\"python train-model-signature.py --training_data diabetes.csv\",\n",
    "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
    "    compute=\"aml-cluster\",\n",
    "    display_name=\"diabetes-train-signature\",\n",
    "    experiment_name=\"diabetes-training\"\n",
    "    )\n",
    "\n",
    "# submit job\n",
    "returned_job = ml_client.create_or_update(job)\n",
    "aml_url = returned_job.studio_url\n",
    "print(\"Monitor your job at\", aml_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Studio, navigate to the **diabetes-train-signature** job to explore the overview of the command job you ran. Find the logged artifacts in the **Outputs + logs** tab. Select the `model` folder to find the `MLmodel` file and explore its contents.\n",
    "\n",
    "Compare the `MLmodel` files with the previous runs. You'll notice that the signature is different from the previous runs. Previous runs used tensor-based signatures, whereas the latest run used a column-based signature."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model\n",
    "\n",
    "When you choose a model you want to deploy, you can first register the model. \n",
    "\n",
    "To register the latest model, you'll refer to the name of the job run. By registering the model as an MLflow model, you can easily deploy it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "job_name = returned_job.name\n",
    "\n",
    "run_model = Model(\n",
    "    path=f\"azureml://jobs/{job_name}/outputs/artifacts/paths/model/\",\n",
    "    name=\"mlflow-diabetes\",\n",
    "    description=\"Model created from run.\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    ")\n",
    "# Uncomment after adding required details above\n",
    "ml_client.models.create_or_update(run_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Studio, navigate to the **Models** page. In the model list, find the `mlflow-diabetes` model and select it to explore it further.\n",
    "\n",
    "- In the **Details** tab of the `mlflow-diabetes` model, you can review that it's a `MLFLOW` type model and the job that trained the model.\n",
    "- In the **Artifacts** tab you can find the directory with the `MLmodel` file.\n",
    "\n",
    "If you want to explore the model's behavior further, you can **optionally** choose to deploy the model to a real-time endpoint."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
