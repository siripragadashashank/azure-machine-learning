{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a responsible AI dashboard to evaluate your models\n",
    "\n",
    "When you compare and evaluate your machine learning models, you'll want to review more than just their performance metric. Azure Machine Learning allows you to create responsible AI dashboard to explore how the model performs on different cohorts of the data. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "To create the responsible AI dashboard, you'll need a training and test dataset, stored as Parquet files and registered as data assets.\n",
    "\n",
    "The data is currently stored as CSV files. Let's convert them to Parquet files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "gather": {
     "logged": 1677025462688
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:15:10.701700500Z",
     "start_time": "2024-06-19T06:15:09.828994300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Pregnancies  PlasmaGlucose  DiastolicBloodPressure  TricepsThickness  \\\n0            0            171                      80                34   \n1            8             92                      93                47   \n2            7            115                      47                52   \n3            9            103                      78                25   \n4            1             85                      59                27   \n\n   SerumInsulin        BMI  DiabetesPedigree  Age  Diabetic  \n0            23  43.509726          1.213191   21         0  \n1            36  21.240576          0.158365   23         0  \n2            35  41.511523          0.079019   23         0  \n3           304  29.582192          1.282870   43         1  \n4            35  42.604536          0.549542   22         0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>PlasmaGlucose</th>\n      <th>DiastolicBloodPressure</th>\n      <th>TricepsThickness</th>\n      <th>SerumInsulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigree</th>\n      <th>Age</th>\n      <th>Diabetic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>171</td>\n      <td>80</td>\n      <td>34</td>\n      <td>23</td>\n      <td>43.509726</td>\n      <td>1.213191</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8</td>\n      <td>92</td>\n      <td>93</td>\n      <td>47</td>\n      <td>36</td>\n      <td>21.240576</td>\n      <td>0.158365</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>115</td>\n      <td>47</td>\n      <td>52</td>\n      <td>35</td>\n      <td>41.511523</td>\n      <td>0.079019</td>\n      <td>23</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>103</td>\n      <td>78</td>\n      <td>25</td>\n      <td>304</td>\n      <td>29.582192</td>\n      <td>1.282870</td>\n      <td>43</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>85</td>\n      <td>59</td>\n      <td>27</td>\n      <td>35</td>\n      <td>42.604536</td>\n      <td>0.549542</td>\n      <td>22</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read training and test dataset\n",
    "df_training = pd.read_csv(\"train-data/diabetes.csv\")\n",
    "df_test = pd.read_csv(\"test-data/diabetes-test.csv\")\n",
    "\n",
    "# display the first few rows of the training dataset\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "gather": {
     "logged": 1677025466902
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:15:16.044925Z",
     "start_time": "2024-06-19T06:15:15.973927500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "# convert data to table\n",
    "table_training = pa.Table.from_pandas(df_training)\n",
    "table_test = pa.Table.from_pandas(df_test)\n",
    "\n",
    "# write tables out to parquet\n",
    "pq.write_table(table_training, \"train-data/diabetes-training.parquet\", version=\"1.0\")\n",
    "pq.write_table(table_test, \"test-data/diabetes-test.parquet\", version=\"1.0\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before you continue\n",
    "\n",
    "You'll need the latest version of the **azureml-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
    "\n",
    "> **Note**:\n",
    "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "gather": {
     "logged": 1677025474944
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:15:23.728564100Z",
     "start_time": "2024-06-19T06:15:20.225509600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: azure-ai-ml\n",
      "Version: 1.14.0\n",
      "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
      "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
      "Author: Microsoft Corporation\n",
      "Author-email: azuresdkengsysadmins@microsoft.com\n",
      "License: MIT License\n",
      "Location: c:\\users\\sirip\\miniconda3\\envs\\myenv\\lib\\site-packages\n",
      "Requires: azure-common, azure-core, azure-mgmt-core, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, msrest, opencensus-ext-azure, opencensus-ext-logging, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show azure-ai-ml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to your workspace\n",
    "\n",
    "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "gather": {
     "logged": 1677025488380
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:15:27.277048Z",
     "start_time": "2024-06-19T06:15:23.732566500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x00000225E92BCE50>,\n         subscription_id=73a3b9d4-4ac9-4810-8752-0f69cc4ac4a3,\n         resource_group_name=DS_Team,\n         workspace_name=mlw-example)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import command\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "subscription_id = os.getenv('SUBSCRIPTION_ID')\n",
    "resource_group = os.getenv('RESOURCE_GROUP')\n",
    "workspace = os.getenv('WORKSPACE')\n",
    "storage_account_name = os.getenv('STORAGE_ACCOUNT_NAME')\n",
    "storage_account_key = os.getenv('STORAGE_ACCOUNT_KEY')\n",
    "\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(), subscription_id, resource_group, workspace\n",
    ")\n",
    "\n",
    "ml_client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data assets\n",
    "\n",
    "To create the responsible AI dashboard, you need to register the training and testing datasets as **MLtable** data assets. The MLtable data assets reference the Parquet files you created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "gather": {
     "logged": 1677025520971
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:16:05.287710300Z",
     "start_time": "2024-06-19T06:16:05.276714700Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = \"train-data/\"\n",
    "test_data_path = \"test-data/\"\n",
    "data_version = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "gather": {
     "logged": 1677025542446
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:16:51.781531600Z",
     "start_time": "2024-06-19T06:16:42.545954400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mUploading train-data (0.71 MBs): 100%|##########| 708302/708302 [00:01<00:00, 510673.15it/s]\n",
      "\u001B[39m\n",
      "\n",
      "\u001B[32mUploading test-data (0.36 MBs): 100%|##########| 358100/358100 [00:00<00:00, 405565.52it/s]\n",
      "\u001B[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "input_train_data = \"diabetes_train_mltable\"\n",
    "input_test_data = \"diabetes_test_mltable\"\n",
    "\n",
    "try:\n",
    "    # Try getting data already registered in workspace\n",
    "    train_data = ml_client.data.get(\n",
    "        name=input_train_data,\n",
    "        version=data_version,\n",
    "    )\n",
    "    test_data = ml_client.data.get(\n",
    "        name=input_test_data,\n",
    "        version=data_version,\n",
    "    )\n",
    "except Exception as e:\n",
    "    train_data = Data(\n",
    "        path=train_data_path,\n",
    "        type=AssetTypes.MLTABLE,\n",
    "        description=\"RAI diabetes training data\",\n",
    "        name=input_train_data,\n",
    "        version=data_version,\n",
    "    )\n",
    "    ml_client.data.create_or_update(train_data)\n",
    "\n",
    "    test_data = Data(\n",
    "        path=test_data_path,\n",
    "        type=AssetTypes.MLTABLE,\n",
    "        description=\"RAI diabetes test data\",\n",
    "        name=input_test_data,\n",
    "        version=data_version,\n",
    "    )\n",
    "    ml_client.data.create_or_update(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the pipeline to create the responsible AI dashboard\n",
    "\n",
    "To create the dashboard, you'll build a pipeline with prebuilt components that are registered by default in the Azure Machine Learning workspace."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLClient(credential=<azure.identity._credentials.default.DefaultAzureCredential object at 0x00000225E83BDF90>,\n",
      "         subscription_id=6c6683e9-e5fe-4038-8519-ce6ebec2ba15,\n",
      "         resource_group_name=registry-builtin-prod-eastus-01,\n",
      "         workspace_name=None)\n"
     ]
    }
   ],
   "source": [
    "# Get handle to azureml registry for the RAI built in components\n",
    "registry_name = \"azureml\"\n",
    "ml_client_registry = MLClient(\n",
    "    credential=DefaultAzureCredential(),\n",
    "    subscription_id=ml_client.subscription_id,\n",
    "    resource_group_name=ml_client.resource_group_name,\n",
    "    registry_name=registry_name,\n",
    ")\n",
    "print(ml_client_registry)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-19T06:24:34.460359300Z",
     "start_time": "2024-06-19T06:24:32.853338100Z"
    }
   },
   "execution_count": 10
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the model\n",
    "\n",
    "A machine learning model has already been trained for you. The model predicts whether a patient has diabetes. All model files are stored in the `model` folder. \n",
    "\n",
    "Register the model by pointing to the `model` folder and its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "gather": {
     "logged": 1677025596451
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:17:58.672629900Z",
     "start_time": "2024-06-19T06:17:53.726887500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32mUploading model (0.0 MBs): 100%|##########| 2342/2342 [00:00<00:00, 3286.38it/s]\n",
      "\u001B[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "file_model = Model(\n",
    "    path=\"model\",\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    "    name=\"local-mlflow-diabetes\",\n",
    "    description=\"Model created from local file.\",\n",
    ")\n",
    "model = ml_client.models.create_or_update(file_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the pipeline\n",
    "\n",
    "To create the responsible AI dashboard, you'll create a pipeline using the prebuilt components. You can choose which components to use, and which features you want to include in your dashboard. You'll create a dashboard that includes error analysis and model interpretability. \n",
    "\n",
    "Next to the responsible AI features, a pipeline to build a dashboard needs to include a component at the start to construct the dashboard, and a component at the end to gather all generated insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "gather": {
     "logged": 1677025619196
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:18:45.457399200Z",
     "start_time": "2024-06-19T06:18:45.453295400Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = model.name\n",
    "expected_model_id = f\"{model_name}:1\"\n",
    "azureml_model_id = f\"azureml:{expected_model_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "gather": {
     "logged": 1677025626888
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:25:02.492692500Z",
     "start_time": "2024-06-19T06:25:00.397724400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current version of RAI built-in components is: 0.14.0\n"
     ]
    }
   ],
   "source": [
    "label = \"latest\"\n",
    "\n",
    "rai_constructor_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_insight_constructor\", label=label\n",
    ")\n",
    "\n",
    "# we get latest version and use the same version for all components\n",
    "version = rai_constructor_component.version\n",
    "print(\"The current version of RAI built-in components is: \" + version)\n",
    "\n",
    "rai_erroranalysis_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_erroranalysis\", version=version\n",
    ")\n",
    "\n",
    "rai_explanation_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_explanation\", version=version\n",
    ")\n",
    "\n",
    "rai_gather_component = ml_client_registry.components.get(\n",
    "    name=\"microsoft_azureml_rai_tabular_insight_gather\", version=version\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you've retrieved all components you want to use, you can build the pipeline and connect the components in the appropriate order:\n",
    "\n",
    "1. Construct the dashboard.\n",
    "1. Add error analysis.\n",
    "1. Add explanations.\n",
    "1. Gather all insights and visualize them in the dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1677026156980
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:26:28.291834900Z",
     "start_time": "2024-06-19T06:26:28.234837800Z"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input, dsl\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "compute_name = \"basic-example\"\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=compute_name,\n",
    "    description=\"RAI insights on diabetes data\",\n",
    "    experiment_name=f\"RAI_insights_{model_name}\",\n",
    ")\n",
    "def rai_decision_pipeline(\n",
    "    target_column_name, train_data, test_data\n",
    "):\n",
    "    # Initiate the RAIInsights\n",
    "    create_rai_job = rai_constructor_component(\n",
    "        title=\"RAI dashboard diabetes\",\n",
    "        task_type=\"classification\",\n",
    "        model_info=expected_model_id,\n",
    "        model_input=Input(type=AssetTypes.MLFLOW_MODEL, path=azureml_model_id),\n",
    "        train_dataset=train_data,\n",
    "        test_dataset=test_data,\n",
    "        target_column_name=target_column_name,\n",
    "    )\n",
    "    create_rai_job.set_limits(timeout=300)\n",
    "\n",
    "    # Add error analysis\n",
    "    error_job = rai_erroranalysis_component(\n",
    "        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "    )\n",
    "    error_job.set_limits(timeout=300)\n",
    "\n",
    "    # Add explanations\n",
    "    explanation_job = rai_explanation_component(\n",
    "        rai_insights_dashboard=create_rai_job.outputs.rai_insights_dashboard,\n",
    "        comment=\"add explanation\", \n",
    "    )\n",
    "    explanation_job.set_limits(timeout=300)\n",
    "\n",
    "    # Combine everything\n",
    "    rai_gather_job = rai_gather_component(\n",
    "        constructor=create_rai_job.outputs.rai_insights_dashboard,\n",
    "        insight_3=error_job.outputs.error_analysis,\n",
    "        insight_4=explanation_job.outputs.explanation,\n",
    "    )\n",
    "    rai_gather_job.set_limits(timeout=300)\n",
    "\n",
    "    rai_gather_job.outputs.dashboard.mode = \"upload\"\n",
    "\n",
    "    return {\n",
    "        \"dashboard\": rai_gather_job.outputs.dashboard,\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the pipeline has been built, you need to define the two necessary inputs: the training and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "gather": {
     "logged": 1677025638275
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:26:33.489817500Z",
     "start_time": "2024-06-19T06:26:33.475822Z"
    }
   },
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input\n",
    "target_feature = \"Diabetic\"\n",
    "\n",
    "diabetes_train_pq = Input(\n",
    "    type=\"mltable\",\n",
    "    path=f\"azureml:{input_train_data}:{data_version}\",\n",
    "    mode=\"download\",\n",
    ")\n",
    "diabetes_test_pq = Input(\n",
    "    type=\"mltable\",\n",
    "    path=f\"azureml:{input_test_data}:{data_version}\",\n",
    "    mode=\"download\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll put everything together: assign the inputs to the pipeline and set the target column (the predicted label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1677026333108
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:26:36.603774500Z",
     "start_time": "2024-06-19T06:26:36.455775900Z"
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from azure.ai.ml import Output\n",
    "\n",
    "# Pipeline to construct the RAI Insights\n",
    "insights_pipeline_job = rai_decision_pipeline(\n",
    "    target_column_name=\"Diabetic\",\n",
    "    train_data=diabetes_train_pq,\n",
    "    test_data=diabetes_test_pq,\n",
    ")\n",
    "\n",
    "# Workaround to enable the download\n",
    "rand_path = str(uuid.uuid4())\n",
    "insights_pipeline_job.outputs.dashboard = Output(\n",
    "    path=f\"azureml://datastores/workspaceblobstore/paths/{rand_path}/dashboard/\",\n",
    "    mode=\"upload\",\n",
    "    type=\"uri_folder\",\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline\n",
    "\n",
    "When you've successfully built the pipeline, you can submit it. The following code will submit the pipeline and check the status of the pipeline. You can also view the pipeline's status in the studio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "gather": {
     "logged": 1677026340892
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "ExecuteTime": {
     "end_time": "2024-06-19T06:35:34.557558800Z",
     "start_time": "2024-06-19T06:26:43.960522400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline job can be accessed in the following URL:\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<a href=\"https://ml.azure.com/runs/crimson_insect_1kbs3lqj69?wsid=/subscriptions/73a3b9d4-4ac9-4810-8752-0f69cc4ac4a3/resourcegroups/DS_Team/workspaces/mlw-example&tid=a8eec281-aaa3-4dae-ac9b-9a398b9215e7\">https://ml.azure.com/runs/crimson_insect_1kbs3lqj69?wsid=/subscriptions/73a3b9d4-4ac9-4810-8752-0f69cc4ac4a3/resourcegroups/DS_Team/workspaces/mlw-example&tid=a8eec281-aaa3-4dae-ac9b-9a398b9215e7</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Running\n",
      "Latest status : Failed\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 27\u001B[0m\n\u001B[0;32m     23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m created_job\n\u001B[0;32m     26\u001B[0m \u001B[38;5;66;03m# This is the actual submission\u001B[39;00m\n\u001B[1;32m---> 27\u001B[0m insights_job \u001B[38;5;241m=\u001B[39m \u001B[43msubmit_and_wait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mml_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minsights_pipeline_job\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[15], line 22\u001B[0m, in \u001B[0;36msubmit_and_wait\u001B[1;34m(ml_client, pipeline_job)\u001B[0m\n\u001B[0;32m     20\u001B[0m     created_job \u001B[38;5;241m=\u001B[39m ml_client\u001B[38;5;241m.\u001B[39mjobs\u001B[38;5;241m.\u001B[39mget(created_job\u001B[38;5;241m.\u001B[39mname)\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLatest status : \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(created_job\u001B[38;5;241m.\u001B[39mstatus))\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m created_job\u001B[38;5;241m.\u001B[39mstatus \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCompleted\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m created_job\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from azure.ai.ml.entities import PipelineJob\n",
    "from IPython.core.display import HTML\n",
    "from IPython.display import display\n",
    "import time\n",
    "\n",
    "def submit_and_wait(ml_client, pipeline_job) -> PipelineJob:\n",
    "    created_job = ml_client.jobs.create_or_update(pipeline_job)\n",
    "    assert created_job is not None\n",
    "\n",
    "    print(\"Pipeline job can be accessed in the following URL:\")\n",
    "    display(HTML('<a href=\"{0}\">{0}</a>'.format(created_job.studio_url)))\n",
    "\n",
    "    while created_job.status not in [\n",
    "        \"Completed\",\n",
    "        \"Failed\",\n",
    "        \"Canceled\",\n",
    "        \"NotResponding\",\n",
    "    ]:\n",
    "        time.sleep(30)\n",
    "        created_job = ml_client.jobs.get(created_job.name)\n",
    "        print(\"Latest status : {0}\".format(created_job.status))\n",
    "    assert created_job.status == \"Completed\"\n",
    "    return created_job\n",
    "\n",
    "\n",
    "# This is the actual submission\n",
    "insights_job = submit_and_wait(ml_client, insights_pipeline_job)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the pipeline is completed, you can review the dashboard in the studio. "
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f2b2cd046deda8eabef1e765a11d0ec9aa9bd1d31d56ce79c815a38c323e14ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
